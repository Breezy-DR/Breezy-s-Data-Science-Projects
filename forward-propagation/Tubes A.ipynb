{"cells":[{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"be44f6c9f21e4ee1946e9c24a85f5598","deepnote_cell_type":"text-cell-p"},"source":"","block_group":"79f13aedbaa648b6938f46b0d4dc48db"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"6f8cb83227a7413a8fc62e3786d407c0","deepnote_cell_type":"text-cell-h1"},"source":"# Tugas Besar IF3270 Pembelajaran Mesin \rArtificial Neural Network\r\nBagian A - Implementasi Forward Propagation untuk Feed Forward Neural Network","block_group":"c93424b4bbe1480cb8d8ae935951a12f"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"d07b23be5235484387d464af19c45bbc","deepnote_cell_type":"text-cell-h2"},"source":"## Kontributor:","block_group":"eae9d93771e54b8c908271cf37a6690c"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"6f47f4389fca4a29a985303f04ab4f52","deepnote_cell_type":"text-cell-bullet"},"source":"- Kartini Copa (13521026)","block_group":"491d0fbbca31463baff8893344dd5345"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"e18a5c4bf03c443489b27b2da8521b96","deepnote_cell_type":"text-cell-bullet"},"source":"- Muhammad Equilibrie Fajria (13521047)","block_group":"89a01f54080d440fb74e9b21126a7d0f"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"2e96b82322cc45459259cc80fb345c86","deepnote_cell_type":"text-cell-bullet"},"source":"- M Farrel Danendra Rachim (13521048)","block_group":"7474b23aa9e44237850b45b1866d53fb"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"73c84fa6475346c78820af7174449b89","deepnote_cell_type":"text-cell-bullet"},"source":"- Fakih Anugerah Pratama (13521091)","block_group":"d1b07d302f9447b686cbad38a5953f25"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"51fe6a2043594f9cbaeba393fcbe6a50","deepnote_cell_type":"text-cell-h2"},"source":"## Activation Function","block_group":"692151f183514c58ad01c711d796f3c4"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1713324838651,"execution_millis":66,"deepnote_to_be_reexecuted":false,"cell_id":"85cd104cd6ab419dab808e1acf75f66a","deepnote_cell_type":"code"},"source":"import math\nimport numpy as np","block_group":"d797312323944bff8e57fa14067ff94e","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1713324838652,"execution_millis":66,"deepnote_to_be_reexecuted":false,"cell_id":"1b9cea1ff2e04e35b2e737218f412704","deepnote_cell_type":"code"},"source":"def fLinear(net):\n    return net\n\ndef fRelu(net):\n    return max(0, net)\n\ndef fSigmoid(net):\n    return 1 / (1 + np.exp(-net))\n\ndef fSoftmax(net):\n    return np.exp(net)\n\nactivationFunctions = {\n    'linear': fLinear,\n    'relu': fRelu,\n    'sigmoid': fSigmoid,\n    'softmax': fSoftmax\n}","block_group":"76fadedf8e214656b3083a3a93bfc415","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"ff70e33e35ff437494e40da0a7697c9f","deepnote_cell_type":"text-cell-h2"},"source":"## Loader","block_group":"dd77457578674e48b0b266764a48e327"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1713324838653,"execution_millis":309,"deepnote_to_be_reexecuted":false,"cell_id":"8722384e2d0f4cd180996a7bdcb4f187","deepnote_cell_type":"code"},"source":"import json\n\nclass Loader:\n    def load_data(filename):\n        base_path = '/work/'\n        with open(base_path + filename, 'r') as file:\n            data = json.load(file)\n    \n        # model data\n        __model = data['case']['model']\n\n        ## input layer\n        input_size = __model['input_size']\n\n        ## hidden and output layer\n        __layers = __model['layers']\n        layers = [[_layer['number_of_neurons'], _layer['activation_function']] for _layer in __layers]\n\n        ## weights\n        weights = data['case']['weights']\n\n        # test\n        ## input data\n        input_data = data['case']['input']\n\n        ## output expectation\n        expected_output = data['expect']['output']\n        max_sse = data['expect']['max_sse']\n\n\n        # return loaded data\n        return input_size, layers, weights, input_data, expected_output, max_sse\n\ninput_size, layers, weights, input_data, expected_output, max_sse = Loader.load_data('multilayer.json')\n\nprint(\"Input Size:\")\nprint(input_size)\nprint(\"Layers\")\nprint(layers)\nprint(\"\\nWeights:\")\nprint(weights)\nprint(\"Input Data:\")\nprint(input_data)\nprint(\"\\nExpected Output:\")\nprint(expected_output)\nprint(\"\\nsse output:\")\nprint(max_sse)","block_group":"16e0a1995eb440a99a221893487b781d","execution_count":null,"outputs":[{"name":"stdout","text":"Input Size:\n3\nLayers\n[[4, 'relu'], [3, 'relu'], [2, 'relu'], [1, 'sigmoid']]\n\nWeights:\n[[[0.1, 0.2, 0.3, -1.2], [-0.5, 0.6, 0.7, 0.5], [0.9, 1.0, -1.1, -1.0], [1.3, 1.4, 1.5, 0.1]], [[0.1, 0.1, 0.3], [-0.4, 0.5, 0.6], [0.7, 0.4, -0.9], [0.2, 0.3, 0.4], [-0.1, 0.2, 0.1]], [[0.1, 0.2], [-0.3, 0.4], [0.6, 0.1], [0.1, -0.4]], [[0.1], [-0.2], [0.3]]]\nInput Data:\n[[-1.0, 0.5, 0.8]]\n\nExpected Output:\n[[0.4846748]]\n\nsse output:\n1e-06\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/18778eee-0b64-41e0-bfeb-9fd011b9cbaa","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"930441162c324005a5208bcd52dfdbc9","deepnote_cell_type":"text-cell-h2"},"source":"## Node","block_group":"7968e8912a534c50b87abee368d0b3a0"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1713324838966,"execution_millis":17,"deepnote_to_be_reexecuted":false,"cell_id":"4bda13e97b0d4218964be897acb47d5a","deepnote_cell_type":"code"},"source":"class Node:\n    def __init__(self, nodeId : int, layerId : int, weight : [float] = None, isBias: bool = False) -> None:\n        self.nodeId = nodeId\n        self.layerId = layerId\n        self.weight = weight\n        self.bias = isBias\n\n    def showInfo(self) -> None:\n        if (self.bias):\n            print(f\"      Bias:\")\n        else:\n            print(f\"      Node {self.nodeId}:\")\n        print(f\"         Weight: {self.weight}\")","block_group":"1a699b8476bc43cd85bea30e1cc5b663","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"ea35c24ba99a4bc5b928bdce59b3f431","deepnote_cell_type":"text-cell-h2"},"source":"## Layer","block_group":"73b58d20f0d344d9af34af97f2b2d0d4"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1713324838974,"execution_millis":36,"deepnote_to_be_reexecuted":false,"cell_id":"13d705b33cfb477cb8fc8eb1499352f6","deepnote_cell_type":"code"},"source":"# layerType = \"hidden\", \"input\", \"output\"\nHIDDEN = \"hidden\"\nINPUT = \"input\"\nOUTPUT = \"output\"\n\nclass Layer:\n    def __init__(self, layerId : int, neuronCount: int, nodeList, layerType: str, activationFunction : str = None) -> None:\n        self.layerId = layerId\n        self.neuronCount = neuronCount\n        self.nodeList = nodeList\n        self.layerType = layerType\n        self.activationFunction = activationFunction\n\n    def calculateNet(self, inputList):\n        net = []\n        nextNeuronSize = len(self.nodeList[0].weight)\n\n        for i in range (nextNeuronSize):\n            sum = self.nodeList[0].weight[i]\n            for j in range (len(inputList)):\n                sum += self.nodeList[j+1].weight[i] * inputList[j]\n            \n            net.append(sum)\n\n        return net\n\n    def showInfo(self) -> None:\n        print(f\"Layer {self.layerId}:\")\n        print(f\"   Type: {self.layerType}\")\n        print(f\"   Neuron Count: {self.neuronCount}\")\n        print(f\"   Activation Function: {self.activationFunction}\")\n        print(f\"   Nodes:\")\n        for node in self.nodeList:\n            if (self.layerType != OUTPUT or (not node.bias)):\n                node.showInfo()\n        print()","block_group":"2a1d2d6618c0453e8fa93b17ee2d765e","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"0241625f80764118b63e681925747466","deepnote_cell_type":"text-cell-h2"},"source":"## Model","block_group":"2d6350bd9c634da7b9012b352088396f"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1713324839015,"execution_millis":83,"deepnote_to_be_reexecuted":false,"cell_id":"992def6a03e4489da324eb3304a4c5e2","deepnote_cell_type":"code"},"source":"class Model:\n    def __init__(self, input_size, layers, weights):\n        self.layers = []\n\n        # input layer\n        _nodes = [Node(i, 0, weights[0][i], True if i == 0 else False) for i in range(input_size + 1)]\n        self.layers.append(Layer(0, input_size, _nodes, INPUT))\n\n        # hidden and output layer\n        for j in range (len(layers)):\n            layerId = j + 1\n            neuronCount = layers[j][0]\n            activationFunction = layers[j][1]\n            layerType = \"\"\n\n            if (j != len(layers)-1):\n                _nodes = [Node(i, layerId, weights[j+1][i], True if i == 0 else False) for i in range(neuronCount + 1)]\n                layerType = HIDDEN\n            else:\n                _nodes = [Node(i, j+1, [], True if i == 0 else False) for i in range (neuronCount + 1)]\n                layerType = OUTPUT\n                \n            self.layers.append(Layer(layerId, neuronCount, _nodes, layerType, activationFunction))","block_group":"0002089362b7482aadd75e1908374d07","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"a80c985b50664193b1ee9b20c1199cc9","deepnote_cell_type":"text-cell-h2"},"source":"## FFNN","block_group":"7a407aa86b7d4eb484021077298cc34b"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1713324839021,"execution_millis":197,"deepnote_to_be_reexecuted":false,"cell_id":"e813f3bb35384ffbb646f46c513f5034","deepnote_cell_type":"code"},"source":"import copy\n\nclass FFNN:\n    def __init__(self, model) -> None:\n        self.layerList = model.layers\n\n    # Predict a single input\n    def predict(self, inputList):  \n        output = copy.deepcopy(inputList)\n        net = [] \n\n        for layer in self.layerList:\n            if (layer.layerType != INPUT):\n                output = [activationFunctions[layer.activationFunction](x) for x in net]\n                if (layer.activationFunction == \"softmax\"):\n                    sigma = sum(output)\n                    for i in range (len(output)):\n                       output[i] /= sigma\n            if (layer.layerType != OUTPUT):\n                net = layer.calculateNet(output)\n\n        return output\n\n    # Predict multiple input\n    def predictMultiple(self, inputList):\n        res = []\n        for val in inputList:\n            res.append(self.predict(val))\n        return res\n\n    def showInfo(self) -> None:\n        print(\"--------------------------------------------------------------------------------\")\n        print(\"ANN Model:\")\n        print()\n        for layer in self.layerList:\n            layer.showInfo()\n        print(\"--------------------------------------------------------------------------------\")","block_group":"a72a972504b04d5e916ee85c65dd3eaa","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"is_collapsed":false,"formattedRanges":[],"deepnote_app_block_visible":false,"cell_id":"18cd1b1db9e04bff8f1f896e1123312f","deepnote_cell_type":"text-cell-h2"},"source":"## Main Program","block_group":"fc5e5aa548e64f6c86fb8ee2c128f6bc"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1713324839068,"execution_millis":277,"deepnote_to_be_reexecuted":false,"cell_id":"24870dbba9fa4dd8b3cc626d10286701","deepnote_cell_type":"code"},"source":"input_size, layers, weights, input_data, expected_output, max_sse = Loader.load_data('tes.json')\nmodel = Model(input_size, layers, weights)\n\nffnn = FFNN(model)\nffnn.showInfo()\n\nfm = ffnn.predictMultiple(input_data)\nprint(\"Predictions:\")\nprint(fm)\nprint()\nprint(\"Expected:\")\nprint(expected_output)\nprint()","block_group":"440538407b9a469283de13fed3bc9034","execution_count":null,"outputs":[{"name":"stdout","text":"--------------------------------------------------------------------------------\nANN Model:\n\nLayer 0:\n   Type: input\n   Neuron Count: 2\n   Activation Function: None\n   Nodes:\n      Bias:\n         Weight: [30]\n      Node 1:\n         Weight: [-20]\n      Node 2:\n         Weight: [-20]\n\nLayer 1:\n   Type: hidden\n   Neuron Count: 1\n   Activation Function: sigmoid\n   Nodes:\n      Bias:\n         Weight: [-25, 20, -10]\n      Node 1:\n         Weight: [20, -10, 10]\n\nLayer 2:\n   Type: output\n   Neuron Count: 3\n   Activation Function: sigmoid\n   Nodes:\n      Node 1:\n         Weight: []\n      Node 2:\n         Weight: []\n      Node 3:\n         Weight: []\n\n--------------------------------------------------------------------------------\nPredictions:\n[[0.006686817475015197, 0.9999546227353499, 0.49988650533019335]]\n\nExpected:\n[[0, 0, 0]]\n\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/25488d37-9b44-4714-bf33-c2785d468e36","content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=afc3e09d-2ff9-42fe-8178-5c8617fbb136' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_persisted_session":{"createdAt":"2024-04-17T04:00:10.608Z"},"deepnote_full_width":true,"deepnote_notebook_id":"cf438e9c48c24b5682ed8864b2b02e2d","deepnote_execution_queue":[]}}