{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latihan Praktikum IF3270 2023/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pembuatan model Machine Learning pada umumnya terdiri atas 5 bagian, yaitu:\n",
    "\n",
    "1. Pengumpulan data\n",
    "2. Pemahaman dan pemrosesan data\n",
    "3. Pembuatan model\n",
    "4. Evaluasi dan tuning model\n",
    "5. Model final\n",
    "\n",
    "\n",
    "Pada notebook ini, diharapkan dapat mengimplementasikan sebagian dari tahapan tersebut sebagai latihan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset yang digunakan adalah [Stroke Prediction Dataset](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset). Berikut adalah deskripsi setiap kolom dari dataset (diperoleh dari sumber).\n",
    "\n",
    "1) **id**: unique identifier\n",
    "2) **gender**: \"Male\", \"Female\" or \"Other\"\n",
    "3) **age**: age of the patient\n",
    "4) **hypertension**: 0 if the patient doesn't have hypertension, 1 if the patient has hypertension\n",
    "5) **heart_disease**: 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease\n",
    "6) **ever_married**: \"No\" or \"Yes\"\n",
    "7) **work_type**: \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\"\n",
    "8) **Residence_type**: \"Rural\" or \"Urban\"\n",
    "9) **avg_glucose_level**: average glucose level in blood\n",
    "10) **bmi**: body mass index\n",
    "11) **smoking_status**: \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"*\n",
    "12) **stroke**: 1 if the patient had a stroke or 0 if not\n",
    "*Note: \"Unknown\" in smoking_status means that the information is unavailable for this patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library di sini\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"healthcare-dataset-stroke-data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Pemahaman dan Pemrosesan Data\n",
    "\n",
    "Tahap ini bertujuan untuk memahami ciri dataset serta setiap fitur yang ada pada dataset. Secara garis besar, hal yang dicari pada tahap ini adalah\n",
    "\n",
    "1. Ukuran data\n",
    "2. Statistik setiap fitur\n",
    "3. Data pencilan (outlier)\n",
    "4. Korelasi\n",
    "5. Penanganan data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.1. Ukuran Data\n",
    "\n",
    "Tentukan ukuran data secara baris dan kolom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.2. Statistik setiap fitur\n",
    "\n",
    "Dibantu penggunaan library Pandas, jawab pertanyaan berikut:\n",
    "1. Kolom apa saja yang merupakan fitur kategorikal?\n",
    "2. Kolom apa saja yang merupakan fitur nonkategorikal?\n",
    "\n",
    "- Untuk setiap kolom kategorikal, tentukan jumlah dari masing-masing kategori pada kolom tersebut\n",
    "- Untuk setiap kolom nonkategorikal, cari nilai minimum, maksimum, median, dan rata-ratanya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.3. Data Pencilan\n",
    "\n",
    "1. Tentukan jika ada missing value dari setiap fitur\n",
    "2. Tentukan outlier dari setiap fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.4. Korelasi\n",
    "\n",
    "Buatlah heatmap dari dataset. Fitur apa yang paling berkorelasi?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.5. Penanganan Data\n",
    "\n",
    "Pada A.1 hingga A.4, kamu telah melakukan pencarian insight pada data. Apabila diperlukan, lakukan analisis mandiri lebih lanjut.\n",
    "\n",
    "Berikutnya, lakukan pemrosesan sebelum dataset dapat digunakan untuk training model. Kamu dapat melakukan berbagai macam pemrosesan, berikut adalah beberapa contohnya.\n",
    "1) Menangani nilai yang hilang: Buang fitur atau ganti nilai yang hilang dengan strategi tertentu.\n",
    "2) Transformasi fitur kategorikal: Ubah menjadi representasi angka seperti penggunaan one-hot encoding atau label encoding\n",
    "3) Scaling: Dapat menggunakan MinMaxScaler, StandardScaler, atau scaler lainnya.\n",
    "4) Membuang fitur yang sekiranya tidak diperlukan.\n",
    "5) Menambah fitur dari fitur yang sudah ada (feature engineering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Design of Experiment\n",
    "Tentukanlah metrik yang akan digunakan pada eksperimen kali ini. Metrik yang dapat lebih dari satu jenis.\n",
    "\n",
    "Metrik utama yang akan digunakan dalam eksperimen adalah F1-score. F1-score adalah hasil rata-rata harmonis dari nilai _precision_ dan _recall_. F1-score mempertimbangkan nilai _precision_ dan _recall_ dan menghasilkan sebuah metrik yang seimbang, sehingga apabila salah satu nilai _precision_ atau _recall_ lebih rendah, salah satu nilai akan menyeimbangkan mettrik lainnya.\n",
    "\n",
    "Nilai F1 yang tinggi melambangkan nilai _precision_ dan _recall_ yang tinggi, dan memberikan hasil yang baik pada permasalahan klasifikasi data yang imbalanced. Akan tetapi, nilai F1 yang rendah sulit memberikan informasi mengenai metrik yang bernilai rendah.\n",
    "\n",
    "Ada beberapa alasan untuk menggunakan F1-score:\n",
    "- F1-score memberikan _measure_ yang lebih baik untuk persoalan dataset yang tidak seimbang. Dalam kasus dataset ini, _instance_ dengan nilai positif lebih banyak dibandingkan _instance_ dengan nilai negatif, sehingga akurasi dapat menjadi metrik yang tidak tepat, sehingga lebih baik menggunakan F1-score yang mempertimbangkan nilai _precision_ dan _recall_\n",
    "- F1-score sudah menggambarkan kemampuan model untuk memprediksi dan mengidentifikasi kelas data positif dan negatif dalam klasifikasi biner\n",
    "- Pada eksperimen ini, akan dilakukan beberapa perbandingan model (_Logistic Regression_, _XGBoost_, hasil hiperparameter, hasil _oversampling / undersampling_, hasil _voting_), dan nilai F1-score cocok digunakan untuk membandingkan kemampuan antar model.\n",
    "\n",
    "\n",
    "Selain F1, metrik lain yang dapat digunakan adalah akurasi, yang menggambarkan seberapa tepat sebuah model dapat melakukan klasifikasi. Nilai akurasi dapat digunakan untuk membandingkan ketepatan klasifikasi dua buah model apabila nilai F1-nya sama."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.1. Dataset Split\n",
    "\n",
    "Lakukan pemisahan antara data training (80%) dan data validasi (20%). Kolom `stroke` adalah target pada dataset ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.2. Baseline Training\n",
    "\n",
    "Lakukan training dengan menggunakan `LogisticRegression`. Evaluasi hasilnya dengan confusion matrix dan deskripsikan dengan singkat hal yang terjadi pada model tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.3. Hyperparameter Tuning\n",
    "\n",
    "Lakukan pengaturan hyperparameter pada model Logistic Regression dan training kembali. Apakah hasilnya berubah?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.4. Training Model Lain\n",
    "\n",
    "Kamu dapat melakukan training dengan model-model lain seperti Random Forest, Decision Tree, dan KNN serta atur hyperparameter-nya. Bandingkan hasilnya dengan baseline Logistic Regression.\n",
    "\n",
    "[Referensi](https://scikit-learn.org/stable/supervised_learning.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Improvement\n",
    "\n",
    "Dataset imbalance merupakan kasus yang umum terjadi saat pembuatan model machine learning. Kasus ini dapat diatasi dengan melakukan oversampling pada target minoritas ataupun undersampling pada dataset mayoritas.\n",
    "\n",
    "[Referensi](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.1. Oversampling\n",
    "\n",
    "Lakukan strategi oversampling pada dataset mayoritas. Training kembali model baseline dan lakukan evaluasi dengan confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.2. Undersampling\n",
    "Lakukan strategi undersampling pada dataset minoritas. Training kembali model dan lakukan evaluasi dengan confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.3. Model Ensembling\n",
    "\n",
    "Sebagai tambahan dari strategi oversampling dan undersampling, kinerja prediksi dapat ditingkatkan dengan membuat beberapa model berbeda menjadi satu model utuh. Contohnya adalah penggabungan Logistic Regression dan Random Forest.\n",
    "\n",
    "Dari scikit-learn, terdapat dua jenis ensembling paling umum yaitu Voting Classifier dan Stacking Classifier. Gunakan kedua strategi ini pada jenis-jenis model yang berbeda, lakukan training pada oversampled atau undersampled data dan bandingkan hasilnya dengan baseline Logistic Regression.\n",
    "\n",
    "[Referensi](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Model Final\n",
    "Tentukan model yang memiliki kinerja terbaik serta berikan alasannya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
